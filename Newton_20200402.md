# Newton会
## lightFMのBPR系の損失について
## 2020-04-02 / AI室 中江 俊博
---
## Newton会の趣旨
- AI室で立ち上げる勉強会の1つ。
- 感染病を避けるために部屋に閉じこもるのであれば、  
  一緒に論文を読み、技術を高めようという趣旨。
- 発表者が興味のあるものであれば、何でも構わない。
  - 特に準備がなくてもよいし、思い付きで話してもよい。
  - 誰かに強制もしないし、ローテーションもしない。

---
## 参考 : wikipediaより
- アイザック・ニュートン
  - ロンドンではペストが大流行しており...、  
    この影響でケンブリッジ大学も閉鎖されることになり、
  - 故郷のウールスソープへと戻り、カレッジですでに得ていた  
    着想について自由に思考する時間を得た。
  - 「ニュートンの三大業績」とされるものは、いずれもペスト禍を逃れて  
    故郷の田舎に戻っていた18か月間の休暇中になしとげたこと

![](./images/newton.jpg)

---
## 本日の話題
- LightFMにおけるBPR系の損失について
- LightFM ([github](https://github.com/lyst/lightfm)) とは
  - Factorization Machines の実装の一つ
- 例

``` python
# Load the MovieLens 100k dataset. Only five
# star ratings are treated as positive.
data = fetch_movielens(min_rating=5.0)

# Instantiate and train the model
model = LightFM(loss='warp')
model.fit(data['train'], epochs=30, num_threads=2)

# Evaluate the trained model
test_precision = precision_at_k(model, data['test'], k=5).mean()
```

---
## Factorization Machinesとは
- 行列分解
  - ユーザ $i$ のアイテム $j$ に対する応答を  
    特徴ベクトル $\boldsymbol{u}_i$ と $\boldsymbol{v}_j$ の内積に分解する
    - $ y_{ij} = \boldsymbol{u}^T_i \boldsymbol{v}_j $
- Factorization Machines (FM)
  - ユーザ・アイテムすべての属性 $i$ をまとめて ${x_i}$ としたとき  
    - $ y = c + \sum_i w_i x_i + \sum_{ij} (\boldsymbol{u}^T_i \boldsymbol{u}_j) x_i x_j $
      - $c$ は定数項
      - $w_i$ は、属性$i$のバイアス項
      - $\boldsymbol{u}_i$ は、属性$i$の特徴ベクトル
- レコメンド精度は行列分解よりFMのほうが高い傾向がある
  - ただし今日の話題の本題ではない。以下、行列分解の前提で考える。

---
## レコメンドデータの種別
- 測定情報の分類
  - explicit feedback
    - ユーザごとのアイテムへの「好み」がすべて得られる場合
    - 例 : すべての映画に対して、好きか嫌いか5段階でランク付けた結果
  - implicit feedback
    - ユーザごとにアイテムに**興味がある場合にのみ**結果が得られる場合
    - 例 : クリック履歴、購入履歴、応募履歴..
      - AI室が扱うレスポンスのほとんどがimplicitである。
- implicit feedback の取り扱い
  - 1. 反応がなかったアイテムをすべて負例(興味なし)として考える
    - 問題 : 負例が膨大になる
  - 2. 反応がなかったアイテムをサンプリングして負例とする
    - negative samplingと呼ばれる

---
## BPR
- BPR: Bayesian Personalized Ranking from Implicit Feedback  
  - [Rendle+ ; 1205.2618](https://arxiv.org/abs/1205.2618)
- 前提
  - ユーザ $i$ は特徴ベクトルの内積 $\boldsymbol{u}^T_i \boldsymbol{v}_j$ が  
    (正に)大きいアイテム $j$ ほど興味がある。
  - ユーザ $i$ が興味のあるアイテム $j$ しかわからない (implicit feedback)
- BPRのロジック : 次の繰り返し
  - ユーザ $i$ をサンプリングして
    - ユーザが反応したアイテム $j$ を1つサンプリング
    - ユーザが反応しなかったアイテム $k$を1つサンプリング
    - 内積の差 $ x_{i,j,k} = \boldsymbol{u}^T_i \boldsymbol{v}_j - \boldsymbol{u}^T_i \boldsymbol{v}_k$ が  
      大きくなるようにパラメータ更新

---
### BPRのパラメータ更新式 (1/2)
- 内積の差 $x_{i,j,k}$ が大きいとは？
  - ユーザ$i$は、負例$k$よりも、正例$j$のほうが興味がある状態。
  - 本来、観測データから計算した内積の差は大きいはずだ。
- 内積の差 $x_{i,j,k}$ は次の確率 $P(x_{i,j,k}) = \sigma(x_{i,j,k})$ に従うとする

$$
\sigma(x) = \frac1{1 + \exp(-x)}
$$

![](./images/loss_function.png)

---
### BPRのパラメータ更新式 (2/2)
- 特徴ベクトルの組 $\Theta$ に基づいて、観測値 $D$ が決まるとする
- $D$ が観測された後のパラメータ $\Theta$ の事後確率は

$$
P(\Theta|D) \propto P(D|\Theta) P(\Theta) = \prod_{i,j,k} P(x_{i,j,k}|\Theta) P(\Theta)
$$

$$ 
\log P(\Theta|D) = \sum_{i,j,k} \log \sigma(x_{i,j,k}) + \log P(\Theta)
$$

$$
\frac{\partial \log P(\Theta|D)}{\partial \Theta} =
  \sum_{i,j,k} \frac{e^{-x_{i,j,k}}}{1 + e^{-x_{i,j,k}}}
  \frac{\partial x_{i,j,k}}{\partial \Theta} - \lambda \Theta
$$
- 最後の式を用いて SGD で更新する。
